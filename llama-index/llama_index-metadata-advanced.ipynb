{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVANZADO. Extracción de Metadata para una mejor indexación y comprensión de un objeto Document en LlamaIndex\n",
    "\n",
    "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_metadata_extractor/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En muchos casos, especialmente cuando tenemos que tratar con documentos largos, un chunk o fragmento de texto puede caracer del contexto necesario para eliminar la ambigüedad entre ese fragmento y otros del mismo Document.\n",
    "\n",
    "Un método para abordar esto es etiquetar manualmente cada fragmento de nuestro conjunto de datos. No obstante, hay que tener en cuenta que esto puede requerir mucho tiempo si tratamos con una gran cantidad de documentos o documentos que se actualizan de manera constante.\n",
    "\n",
    "Para solucionarlo, utilizamos LLMs para extraer cierta información contextual relevante para el documento y así ayudar con la recuperación de la información de manera más efectiva.\n",
    "\n",
    "Se utiliza el módulo Metadata Extractor de LlamaIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tienes que tener instalados los siguientes paquetes\n",
    "\n",
    "# %pip install llama-index-llms-openai\n",
    "# %pip install llama-index-extractors-entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no has ejecutado nunca LlamaIndex también tendrás que instalarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego ejecuta este código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El módulo nest_asyncio se utiliza para permitir el uso de bucles de eventos asyncio anidados en un entorno Jupyter Notebook o en Google Colab. El módulo proporciona un marco para escribir código concurrente utilizando la sintaxis async/await y evitar errores de lógica inesperados.\n",
    "\n",
    "Luego sigue con esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY_HERE\"\n",
    "# O puedes utilizar la funcion load_dotenv del módulo dotenv, pero tendrás que tener creado un archivo .env con la clave OPENAI_API_KEY\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.schema import MetadataMode\n",
    "\n",
    "llm = OpenAI(temperature=0.1, model=\"gpt-3.5-turbo\", max_tokens=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a crear un analizador de nodos que extraerá el título del documento y hipotéticas preguntas relacionadas con el contenido de ese chunk. Instanciamos diferentes clases del módulo extractors como SummartyExtractor y KeywordExtractor, aunque también puedes crear el tuyo utilizando la clase BaseExtractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.extractors import (\n",
    "    SummaryExtractor,\n",
    "    QuestionsAnsweredExtractor,\n",
    "    TitleExtractor,\n",
    "    KeywordExtractor,\n",
    "    BaseExtractor,\n",
    ")\n",
    "from llama_index.extractors.entity import EntityExtractor\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    separator=\" \", chunk_size=512, chunk_overlap=128\n",
    ")\n",
    "\n",
    "class CustomExtractor(BaseExtractor):\n",
    "    def extract(self, nodes):\n",
    "        metadata_list = [\n",
    "            {\n",
    "                \"custom\": (\n",
    "                    node.metadata[\"document_title\"]\n",
    "                    + \"\\n\"\n",
    "                    + node.metadata[\"excerpt_keywords\"]\n",
    "                )\n",
    "            }\n",
    "            for node in nodes\n",
    "        ]\n",
    "        return metadata_list\n",
    "\n",
    "\n",
    "extractors = [\n",
    "    TitleExtractor(nodes=5, llm=llm),\n",
    "    QuestionsAnsweredExtractor(questions=3, llm=llm),\n",
    "    # EntityExtractor(prediction_threshold=0.5),\n",
    "    # SummaryExtractor(summaries=[\"prev\", \"self\"], llm=llm),\n",
    "    # KeywordExtractor(keywords=10, llm=llm),\n",
    "    # CustomExtractor()\n",
    "]\n",
    "\n",
    "transformations = [text_splitter] + extractors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando la fuente de datos de Tesla que introducíamos en este artículo: https://www.codigollm.es/document-llamaindex-que-son-estos-objetos-en-el-contexto-de-los-modelos-llm/, y una vez cargada la información utilizando SimpleDirectoryReader, vamos a aplicar las transformaciones a los documentos que se han generado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.85it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.37it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.71it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.32it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.71it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.53it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "100%|██████████| 45/45 [00:19<00:00,  2.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# Note the uninformative document file name, which may be a common scenario in a production setting\n",
    "# tesla_docs = SimpleDirectoryReader(input_files=[\"data/TSLA-Q1-2024-Update.pdf\"]).load_data()\n",
    "tesla_docs = SimpleDirectoryReader(input_files=[\"data/TSLA-Q1-2024-Update.pdf\"]).load_data()\n",
    "\n",
    "# Nuestro Document tiene un total de 31 objetos\n",
    "# tesla_front_pages = tesla_docs[0:3]\n",
    "# tesla_content = tesla_docs[3:31]\n",
    "# tesla_docs = tesla_front_pages + tesla_content\n",
    "\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "pipeline = IngestionPipeline(transformations=transformations)\n",
    "\n",
    "tesla_nodes = pipeline.run(documents=tesla_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver el resultado mejor vamos a utilizar una función auxiliar para ayudarnos a serializar, es decir, traducir una estructura compleja a un formato que Python pueda manejar, y luego imprimir el resultado más legible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def serialize_and_print_text_node(text_node):\n",
    "    # Convertir el objeto TextNode a un diccionario\n",
    "    text_node_dict = {\n",
    "        'id_': text_node.id_,\n",
    "        'embedding': text_node.embedding,\n",
    "        'metadata': text_node.metadata,\n",
    "        'excluded_embed_metadata_keys': text_node.excluded_embed_metadata_keys,\n",
    "        'excluded_llm_metadata_keys': text_node.excluded_llm_metadata_keys,\n",
    "        'relationships': {\n",
    "            str(relationship): {\n",
    "                'node_id': related_node_info.node_id,\n",
    "                'node_type': str(related_node_info.node_type),\n",
    "                'metadata': related_node_info.metadata,\n",
    "                'hash': related_node_info.hash\n",
    "            }\n",
    "            for relationship, related_node_info in text_node.relationships.items()\n",
    "        },\n",
    "        'text': text_node.text,\n",
    "        'start_char_idx': text_node.start_char_idx,\n",
    "        'end_char_idx': text_node.end_char_idx,\n",
    "        'text_template': text_node.text_template,\n",
    "        'metadata_template': text_node.metadata_template,\n",
    "        'metadata_seperator': text_node.metadata_seperator\n",
    "    }\n",
    "\n",
    "    # Serializar el diccionario a JSON con indentación para una mejor legibilidad\n",
    "    json_data = json.dumps(text_node_dict, indent=2)\n",
    "\n",
    "    # Imprimir el JSON serializado\n",
    "    print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si guardamos el primer objeto que se ha creado text_node = tesla_nodes[0] y lo mostramos a través de la función serialize_and_print_text_node(text_node):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id_\": \"6aee7193-074b-4758-8ed3-234847482740\",\n",
      "  \"embedding\": null,\n",
      "  \"metadata\": {\n",
      "    \"page_label\": \"1\",\n",
      "    \"file_name\": \"TSLA-Q1-2024-Update.pdf\",\n",
      "    \"file_path\": \"data\\\\TSLA-Q1-2024-Update.pdf\",\n",
      "    \"file_type\": \"application/pdf\",\n",
      "    \"file_size\": 7458951,\n",
      "    \"creation_date\": \"2024-06-16\",\n",
      "    \"last_modified_date\": \"2024-06-16\",\n",
      "    \"document_title\": \"Q1 2024 Update: A Comprehensive Overview of Candidate Titles and Content\",\n",
      "    \"questions_this_excerpt_can_answer\": \"1. What is the title of the document that provides a comprehensive overview of candidate titles and content for the Q1 2024 update?\\n2. When was the Q1 2024 update document created and last modified?\\n3. What is the file size of the Q1 2024 update document in PDF format?\"\n",
      "  },\n",
      "  \"excluded_embed_metadata_keys\": [\n",
      "    \"file_name\",\n",
      "    \"file_type\",\n",
      "    \"file_size\",\n",
      "    \"creation_date\",\n",
      "    \"last_modified_date\",\n",
      "    \"last_accessed_date\"\n",
      "  ],\n",
      "  \"excluded_llm_metadata_keys\": [\n",
      "    \"file_name\",\n",
      "    \"file_type\",\n",
      "    \"file_size\",\n",
      "    \"creation_date\",\n",
      "    \"last_modified_date\",\n",
      "    \"last_accessed_date\"\n",
      "  ],\n",
      "  \"relationships\": {\n",
      "    \"NodeRelationship.SOURCE\": {\n",
      "      \"node_id\": \"e50999b2-0ae1-4e6f-81ca-1d6c007ebcba\",\n",
      "      \"node_type\": \"ObjectType.DOCUMENT\",\n",
      "      \"metadata\": {\n",
      "        \"page_label\": \"1\",\n",
      "        \"file_name\": \"TSLA-Q1-2024-Update.pdf\",\n",
      "        \"file_path\": \"data\\\\TSLA-Q1-2024-Update.pdf\",\n",
      "        \"file_type\": \"application/pdf\",\n",
      "        \"file_size\": 7458951,\n",
      "        \"creation_date\": \"2024-06-16\",\n",
      "        \"last_modified_date\": \"2024-06-16\"\n",
      "      },\n",
      "      \"hash\": \"51ddb2059c808497f51114e2f7539269227d9d2b9d1c54601aa9f53bd91619ed\"\n",
      "    }\n",
      "  },\n",
      "  \"text\": \"Q1 2024 Update\\n1\",\n",
      "  \"start_char_idx\": 0,\n",
      "  \"end_char_idx\": 16,\n",
      "  \"text_template\": \"[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n\",\n",
      "  \"metadata_template\": \"{key}: {value}\",\n",
      "  \"metadata_seperator\": \"\\n\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "serialize_and_print_text_node(tesla_nodes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, si algun método de estas clases no nos convence y queremos controlar más el output del modelo, podemos hacer una aproximación diferente utilizando también técnicas de data mining pero de manera más artesana y programando nuestra propia función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configuración de logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Crear una instancia del cliente de OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Definimos una función para extraer las Entities del contenido\n",
    "def get_entity_extraction_prompt(content):\n",
    "    logger.info(\"Generando el prompt para la extracción de entidades.\")\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Extrae las entidades más importantes del texto que te proporcionará el usuario. Identifica entidades como personas, organizaciones, ubicaciones, fechas, cantidades, etc. Devuelve las entidades como una lista separada por comas, así: John Smith, Microsoft, Nueva York, 2023-05-20, $1 millón. Devuelve un máximo de 10 entidades. Si no se encuentran entidades poner: ' '\"},\n",
    "                {\"role\": \"user\", \"content\": f\"{content}\"}\n",
    "            ]\n",
    "        )\n",
    "        logger.info(\"Extracción de entidades completada con éxito.\")\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        logger.error(\"Error al generar la extracción de entidades: %s\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como queremos extraer las Entites de cada chunk hacemos una llamada al modelo con el prompt específico para cada Node o chunk del documento, así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n",
      "INFO:__main__:Generando el prompt para la extracción de entidades.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Extracción de entidades completada con éxito.\n",
      "INFO:__main__:Entidades extraídas correctamente.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodo: 6aee7193-074b-4758-8ed3-234847482740\n",
      "Entidades: ['- 2024']\n",
      "---\n",
      "Nodo: ee07fe10-5eb9-4228-b2ad-83dfa67ba5fe\n",
      "Entidades: [\"  ' '\"]\n",
      "---\n",
      "Nodo: 5c14b804-2cbe-4062-947d-3267523279c6\n",
      "Entidades: ['Red Sea', 'Gigafactory Berlin', 'Fremont', 'Global EV', 'COGS', 'EV adoption', 'Cybertruck', 'regulatory credits', 'AI infrastructure', 'Supercharger.']\n",
      "---\n",
      "Nodo: 80f75ded-6c2f-4999-8c61-b7e9069c6fa4\n",
      "Entidades: ['COGS', 'factories', 'production lines', 'AI', 'FSD', 'Supervised', 'subscription', 'price', 'cash flow', 'Free cash flow', 'AI infrastructure', 'capex', 'cash', 'investments.']\n",
      "---\n",
      "Nodo: ae92be14-1416-4941-aeb8-9768ab80e5ee\n",
      "Entidades: ['Total automotive revenues', 'Energy generation and storage revenue', 'Services and other revenue', 'Total revenues', 'Total gross profit', 'Total GAAP gross margin', 'Operating expenses', 'Income from operations', 'Adjusted EBITDA', 'Net income.']\n",
      "---\n",
      "Nodo: 36461cd3-e483-4fc4-b3d1-70be6fd92d6a\n",
      "Entidades: ['-674%', '22,402', '23,075', '26,077', '29,094', '26,863', '20%', '2,513', '2,703', '1,853', '7,928.']\n",
      "---\n",
      "Nodo: 1510431d-b825-4b29-b21a-762edcc53bad\n",
      "Entidades: ['Revenue Total', '$21.3B', 'Model 3', 'Fremont factory', 'Giga Berlin', 'North America', 'Operating income', '$1.2B', 'Cybertruck', 'cash', '$26.9B', 'free cash flow']\n",
      "---\n",
      "Nodo: 644d9629-d043-4ab8-8106-730db20b8cd9\n",
      "Entidades: ['Q1-2023', 'Q2-2023', 'Q3-2023', 'Q4-2023', 'Model 3/Y', 'Other models', 'Tesla', 'Automotive News', '1,000', '1,068']\n",
      "---\n",
      "Nodo: 8344ee31-46af-43d6-a747-a93fae3fbc7c\n",
      "Entidades: ['California', 'Texas', 'Nevada', 'Washington', 'Berlin', 'Shanghai', 'Cybertruck', 'Tesla Semi', 'Roadster', 'Gigafactory.']\n",
      "---\n",
      "Nodo: ebc2ac45-10bd-480f-b1e6-c81f0690e9a5\n",
      "Entidades: ['Cybertrucks', 'April', 'China', 'Shanghai', 'Gigafactory Shanghai', 'Chinese New Year', 'Q1', 'Chile', 'Europe', 'Berlin-Brandenburg', 'Model Y', 'Red Sea conflict', 'idle capacity charges', 'US/Canada.']\n",
      "---\n",
      "Nodo: 4abfb911-1e8e-4305-b2dc-054b7b2ac9f9\n",
      "Entidades: ['Tesla', 'FSD V12 Miles', 'AI Training Capacity', 'Hardware 4.0', 'U.S.', 'Canada', 'Autopark', 'Cybertruck ramp.']\n",
      "---\n",
      "Nodo: 5d48c1fb-bb6d-4bd7-ad33-f2f59d5dd303\n",
      "Entidades: ['Tesla', 'Megapack', 'Energy Generation', 'Energy Storage', 'Megafactory', 'Lathrop', 'CA', 'North American Supercharger Network', 'OEMs', 'NACS', 'North America.']\n",
      "---\n",
      "Nodo: 97be4cc5-662e-4ef4-982d-ef7779023d78\n",
      "Entidades: ['Model 3/Y platform', '2024', 'Energy Generation and Storage', 'Automotive business', 'AI', 'manufacturing', 'operations', 'fleet-based profits', 'new models', 'manufacturing lines', 'three million vehicles.']\n",
      "---\n",
      "Nodo: 934adf78-118d-495f-b349-bc27d864fd02\n",
      "Entidades: [' ']\n",
      "---\n",
      "Nodo: fd5eb143-a236-4530-bc9f-e408aad18b38\n",
      "Entidades: ['China', 'Global BEV market share', 'World ex-China', 'Renault Group', '120%', '2%', '4%', '6%', '8%', '10%']\n",
      "---\n",
      "Nodo: f485457b-e825-4c75-803a-e4fcdc554859\n",
      "Entidades: ['TESLA', 'VEHÍCULOS']\n",
      "---\n",
      "Nodo: 0ab65ec6-8dc3-466e-b590-8cfc90e50ce4\n",
      "Entidades: ['$299', '$160', 'U.S.', '$1', 'gas savings', '']\n",
      "---\n",
      "Nodo: a084a2aa-184a-4d47-8bbb-ab5a0337a2e6\n",
      "Entidades: ['C Y B E R T R U C K', 'F I N A L   A S S E M B L Y   L I N E']\n",
      "---\n",
      "Nodo: 6af4fd78-bcb7-41c9-9386-791726e29f14\n",
      "Entidades: ['SUPERCHARGER NETWORK', 'NORTH AMERICA', '16']\n",
      "---\n",
      "Nodo: 5beece0b-85dc-4115-88b8-3221cdcf13dd\n",
      "Entidades: ['Tesla', 'Ride-Hailing.']\n",
      "---\n",
      "Nodo: 6ea7b079-a741-451e-8cc7-3e02276ba494\n",
      "Entidades: ['D O J O   T R A I N I N G   C L U S T E R  ']\n",
      "---\n",
      "Nodo: b273b470-f695-4c1d-acac-20e9b0d8080e\n",
      "Entidades: ['MEGAPACK-PLUS', \"Power's Kapolei Energy Storage Facility\"]\n",
      "---\n",
      "Nodo: b29548f0-ad24-4a78-878e-b52ccde89375\n",
      "Entidades: ['TESLA', 'GIGAFACTORY', 'NEVADA']\n",
      "---\n",
      "Nodo: 243e3b21-1a15-40d2-9104-1345082a3c14\n",
      "Entidades: ['COST GRIND']\n",
      "---\n",
      "Nodo: 25df44fc-fac0-4b3c-9ccc-f6f98c0a3b20\n",
      "Entidades: ['$B', 'millions', 'KEYM E T R I C S Q U A R T E R L Y', 'Operating Cash Flow', 'Free Cash Flow', 'Net Income', 'Adjusted EBITDA', '2Q-2021', '3Q-2021', '4Q-2021', '1Q-2022', '2Q-2022', '3Q-2022', '4Q-2022', '1Q-2023', '2Q-2023', '3Q-2023.']\n",
      "---\n",
      "Nodo: 7af2db4c-2719-46ff-b5ab-af69c7a1bd05\n",
      "Entidades: ['Net Income', 'Adjusted EBITDA', 'Vehicle Deliveries', '2Q-2021', '3Q-2021', '4Q-2021', '1Q-2022', '2Q-2022', '3Q-2022', '4Q-2022', '1Q-2023', '2Q-2023', '3Q-2023.']\n",
      "---\n",
      "Nodo: e8209189-30da-440b-bedf-d91218843022\n",
      "Entidades: [\"' '\"]\n",
      "---\n",
      "Nodo: 8758ebe4-987c-48ed-aa95-1b4314b44319\n",
      "Entidades: ['Automotive sales', 'Automotive regulatory credits', 'Automotive leasing', 'Energy generation and storage', 'Services and other', 'REVENUES', 'COST OF REVENUES', 'Gross profit', 'OPERATING EXPENSES', 'Research and development.']\n",
      "---\n",
      "Nodo: 6b670eef-abbd-4c60-9264-10e2b8e5fca8\n",
      "Entidades: ['Research and development', 'Selling', 'general and administrative', 'INCOME FROM OPERATIONS', 'Interest income', 'Interest expense', 'INCOME BEFORE INCOME TAXES', 'Provision for income taxes', 'NET INCOME', 'Net income attributable to common stockholders']\n",
      "---\n",
      "Nodo: e09235dc-9704-40c2-888f-807b13582296\n",
      "Entidades: ['0.37', '0.73', '0.78', '0.53', '2.27', '0.34', '3,166', '3,171', '3,176', '3,181', '3,186']\n",
      "---\n",
      "Nodo: 3386e595-330c-4589-9268-72bff87063c8\n",
      "Entidades: ['Cash', 'cash equivalents', 'investments', 'Accounts receivable', 'Inventory', 'Prepaid expenses', 'Operating lease vehicles', 'Solar energy systems', 'Property', 'plant and equipment', 'Operating lease right-of-use assets.']\n",
      "---\n",
      "Nodo: 5a01f4e5-9773-49a0-9e33-0144b9929cd2\n",
      "Entidades: ['Accounts payable', 'Deferred revenue', 'Total assets', 'LIABILITIES AND EQUITY', 'Total current liabilities', 'Debt and finance leases', 'Total liabilities', 'Redeemable noncontrolling interests in subsidiaries', \"Total stockholders' equity\", 'Noncontrolling interests in subsidiaries.']\n",
      "---\n",
      "Nodo: a36d7549-6d84-4cad-ab0a-a45d9c310c6b\n",
      "Entidades: ['2,539', '2,614', '1,878', '7,943', '1,144', '1,046', '1,154', '1,235', '1,232', '1,246']\n",
      "---\n",
      "Nodo: c3b9fd25-48a6-436f-a1df-9b0187b6cb41\n",
      "Entidades: [\"' '\"]\n",
      "---\n",
      "Nodo: 2ef69f9f-a726-41b0-92c5-258459b6ed30\n",
      "Entidades: ['USD', 'Q1-2023', 'Q2-2023', 'Q3-2023', 'Q4-2023', 'Q1-2024', 'Net income', 'GAAP', 'Stock-based compensation expense', 'Release of valuation allowance', 'Deferred tax assets', 'Non-GAAP', 'Buy-out', 'Noncontrolling interest', 'Diluted EPS', 'Earnings per share', 'Shares', 'Interest expense', 'Income taxes', 'Depreciation', 'Amortization', 'Impairment', 'EBITDA.']\n",
      "---\n",
      "Nodo: 3cf81ebc-831a-4853-bfce-42fa891540ac\n",
      "Entidades: ['income attributable to common stockholders', 'Interest expense', 'Provision for (benefit from) income taxes', 'Depreciation', 'amortization and impairment', 'Stock-based compensation expense', 'Adjusted EBITDA', 'Total revenues', 'Adjusted EBITDA margin', 'R E C O N C I L I A T I O N.']\n",
      "---\n",
      "Nodo: b6c73f98-cdd3-4794-823a-850a350eb6b3\n",
      "Entidades: ['Net cash provided by operating activities', 'Capital expenditures', 'Free cash flow', 'Net income attributable to common stockholders', 'Interest expense', 'TTM', 'GAAP', 'non-GAAP', 'USD.']\n",
      "---\n",
      "Nodo: 63d65504-b87d-47b6-89b4-65358de7373d\n",
      "Entidades: ['TTM', 'USD', 'millones', 'Net income attributable to common stockholders', 'Interest expense', 'Provision for income taxes', 'Depreciation', 'amortization and impairment', 'Stock-based compensation expense', 'Adjusted EBITDA', 'Trailing twelve months.']\n",
      "---\n",
      "Nodo: 0166e802-12e7-477b-be31-0fb52f521861\n",
      "Entidades: ['TTM', 'Trailing twelve months', 'GAAP', 'USD', '3Q-2020', '4Q-2020', '1Q-2021', '2Q-2021', '3Q-2021', '4Q-2021', '1Q-2022', '2Q-2022', '3Q-2022', '4Q-2022.']\n",
      "---\n",
      "Nodo: ae5a33fd-461a-479d-b4ce-8bed54f86783\n",
      "Entidades: ['1Q-2023', '2Q-2023', '3Q-2023', '4Q-2023', '1Q-2024', 'Net income attributable to common stockholders', 'Interest expense', 'Provision for income taxes', 'Depreciation', 'amortization and impairment', 'Stock-based compensation expense.']\n",
      "---\n",
      "Nodo: d596e644-9e83-4f03-aba5-4b2c4b1cc133\n",
      "Entidades: ['Tesla', '4:30 p.m. CT', 'Ap ril 23', '2024', 'ir.tesla.com', 'one year', 'end customers', 'energy product', 'storage projects', 'solar projects', 'Adjusted EBITDA', 'Free cash flow', 'Days sales outstanding.']\n",
      "---\n",
      "Nodo: 044e8e91-2375-4ad3-bdb3-c6de5676979d\n",
      "Entidades: ['GAAP', 'USD', 'NYSE', 'quarter', 'Tesla', 'U.S. GAAP', 'Adjusted EBITDA', 'current results', 'GAAP net income', 'USD', 'management', '75 trading days', '']\n",
      "---\n",
      "Nodo: 609aedbe-3333-41cf-95f4-5193909ce5fc\n",
      "Entidades: ['Tesla', 'U.S. GAAP', 'GAAP', 'Tesla management', 'U.S.', 'lithium-ion cells', 'Tesla products', 'electric vehicles', 'automotive', 'energy product markets', 'battery cells', '']\n",
      "---\n",
      "Nodo: 44449362-33a4-4bfe-a837-1f219c065d24\n",
      "Entidades: ['lithium-ion cells', 'Tesla', 'battery cells', 'international expansion', 'product liability claims', 'competition', 'public credibility', 'government incentives', 'key employees', 'regulations. ']\n",
      "---\n",
      "Nodo: ab4328db-f94e-44ab-a731-9e4eaa165f6a\n",
      "Entidades: ['Es necesario que proporciones un texto del cual pueda extraer las entidades.']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for node in tesla_nodes:\n",
    "    text = node.get_text()\n",
    "    try:\n",
    "        entities = get_entity_extraction_prompt(text)\n",
    "        logger.info(\"Entidades extraídas correctamente.\")\n",
    "        node.metadata[\"entities\"] = entities.split(\", \")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error al extraer entidades: {e}\")\n",
    "        node.metadata[\"entities\"] = [\"Error en la extracción\"]\n",
    "        \n",
    "# Imprimir las entidades extraídas para cada nodo\n",
    "for node in tesla_nodes:\n",
    "    print(f\"Nodo: {node.node_id}\")\n",
    "    print(f\"Entidades: {node.metadata['entities']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y si volvemos a utilizar la función serialize_and_print_text_node(text_node) dónde text_node es text_node = tesla_nodes[1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id_\": \"5c14b804-2cbe-4062-947d-3267523279c6\",\n",
      "  \"embedding\": null,\n",
      "  \"metadata\": {\n",
      "    \"page_label\": \"3\",\n",
      "    \"file_name\": \"TSLA-Q1-2024-Update.pdf\",\n",
      "    \"file_path\": \"data\\\\TSLA-Q1-2024-Update.pdf\",\n",
      "    \"file_type\": \"application/pdf\",\n",
      "    \"file_size\": 7458951,\n",
      "    \"creation_date\": \"2024-06-16\",\n",
      "    \"last_modified_date\": \"2024-06-16\",\n",
      "    \"document_title\": \"\\\"Accelerating Towards Profitable Growth: Tesla's Q1 Performance, Cost Reduction, Scaled Autonomy, and Record Production\\\"\",\n",
      "    \"questions_this_excerpt_can_answer\": \"1. How much did Tesla invest in capital expenditures in Q1 of 2024?\\n2. What challenges did Tesla face in Q1 of 2024, impacting their operations and profitability?\\n3. How has Tesla been working towards increasing EV adoption and supporting their growth through vehicle financing programs and cost-cutting exercises in Q1 of 2024?\",\n",
      "    \"entities\": [\n",
      "      \"Red Sea\",\n",
      "      \"Gigafactory Berlin\",\n",
      "      \"Fremont\",\n",
      "      \"Global EV\",\n",
      "      \"COGS\",\n",
      "      \"EV adoption\",\n",
      "      \"Cybertruck\",\n",
      "      \"regulatory credits\",\n",
      "      \"AI infrastructure\",\n",
      "      \"Supercharger.\"\n",
      "    ]\n",
      "  },\n",
      "  \"excluded_embed_metadata_keys\": [\n",
      "    \"file_name\",\n",
      "    \"file_type\",\n",
      "    \"file_size\",\n",
      "    \"creation_date\",\n",
      "    \"last_modified_date\",\n",
      "    \"last_accessed_date\"\n",
      "  ],\n",
      "  \"excluded_llm_metadata_keys\": [\n",
      "    \"file_name\",\n",
      "    \"file_type\",\n",
      "    \"file_size\",\n",
      "    \"creation_date\",\n",
      "    \"last_modified_date\",\n",
      "    \"last_accessed_date\"\n",
      "  ],\n",
      "  \"relationships\": {\n",
      "    \"NodeRelationship.SOURCE\": {\n",
      "      \"node_id\": \"223d2390-8b07-441a-a8f6-3624476fb2e3\",\n",
      "      \"node_type\": \"ObjectType.DOCUMENT\",\n",
      "      \"metadata\": {\n",
      "        \"page_label\": \"3\",\n",
      "        \"file_name\": \"TSLA-Q1-2024-Update.pdf\",\n",
      "        \"file_path\": \"data\\\\TSLA-Q1-2024-Update.pdf\",\n",
      "        \"file_type\": \"application/pdf\",\n",
      "        \"file_size\": 7458951,\n",
      "        \"creation_date\": \"2024-06-16\",\n",
      "        \"last_modified_date\": \"2024-06-16\"\n",
      "      },\n",
      "      \"hash\": \"171639a488e3806f4439309cb28e9620a6a2e8b0ca1b4790c73074909c1bf1e6\"\n",
      "    },\n",
      "    \"NodeRelationship.NEXT\": {\n",
      "      \"node_id\": \"80f75ded-6c2f-4999-8c61-b7e9069c6fa4\",\n",
      "      \"node_type\": \"ObjectType.TEXT\",\n",
      "      \"metadata\": {},\n",
      "      \"hash\": \"cfbd23c9584454f84551f26df5601329edb220cd380dcd238270a821103d06fd\"\n",
      "    }\n",
      "  },\n",
      "  \"text\": \"S U M M A R Y H I G H L I G H T S\\n(1) Excludes SBC (stock -based compensation), net of tax; (2) Free cash flow = operating cash flow less capex; (3) Includes cash, cash equivalents and investments; (4) Calculated by dividing Cost of Automotive Sales \\nRevenue by respective quarter\\u2019s new deliveries (ex -operating leases); (5)Active driver supervision required; does not make the vehicle autonomous. Profitability $1.2B GAAP operating income in Q1\\n$1.1B GAAP net income in Q1\\n$1.5B non -GAAP net income1 in Q1We experienced numerous challenges in Q1, from the Red Sea conflict and the \\narson attack at Gigafactory Berlin, to the gradual ramp of the updated Model 3 in \\nFremont. Excluding Cybertruck and unscheduled downtime, our COGS4 per unit \\ndeclined sequentially, driven primarily by lower raw material costs.\\nGlobal EV sales continue to be under pressure as many carmakers prioritize hybrids \\nover EVs. While positive for our regulatory credits business, we prefer the industry \\nto continue pushing EV adoption, which is in -line with our mission. To support our \\ngrowth, we have been increasing  awareness and expanding vehicle financing \\nprograms, including attractive leasing terms for our customers.\\nWhile many are pulling back on their investments, we are investing in future growth \\n\\u2013 including our AI infrastructure, production capacity, our Supercharger and service \\nnetworks and new products infrastructure  \\u2013 with $2.8B of capital expenditures in \\nQ1. \\nWe recently undertook a cost -cutting exercise to increase operational efficiency. \\nWe also remain committed to company -wide cost reduction, including reducing \\nCOGS per vehicle. Ultimately, we are focused on profitable growth, including by \\nleveraging existing factories and production lines to introduce new and more \\naffordable products.\\nThe future is not only electric, but also autonomous. We believe scaled autonomy is \\nonly possible with data from millions of vehicles and an immense AI training cluster. \\nWe have, and continue to expand, both. To make FSD (Supervised) 5 more \\naccessible, we reduced the price of subscription to $99/month and the purchase \\nprice to $8,000 in the US.Cash Operating\",\n",
      "  \"start_char_idx\": 0,\n",
      "  \"end_char_idx\": 2173,\n",
      "  \"text_template\": \"[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n\",\n",
      "  \"metadata_template\": \"{key}: {value}\",\n",
      "  \"metadata_seperator\": \"\\n\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "serialize_and_print_text_node(tesla_nodes[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
